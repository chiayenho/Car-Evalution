{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: http://archive.ics.uci.edu/ml/datasets/Car+Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification problem. We want to classify the car into 4 classes, which are unacc, acc, good, and vgood.\n",
    "I approached decision tree, logistic regression, KNN, Navie base, and SVM classification to build the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('car.data', header = None)\n",
    "col_names =['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      " 6   class     1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# check NA and datatype\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "acc       384\n",
       "good       69\n",
       "unacc    1210\n",
       "vgood      65\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count different classes. It shows that it is not imbalanced data\n",
    "df.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:6]\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each x varable is ordinal data. Even though there seems to be a order in the class, for example ['low','med','high','vhigh']. However, since I can't define the distance between each class, I decided to turn into categorical datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "X_ohe = ohe.fit_transform(X).toarray()\n",
    "X = pd.DataFrame(X_ohe)\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#labelencoder = LabelEncoder()\n",
    "#y = labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best model for this dataset among all 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_grid = {'max_depth':list(range(2,10)), 'min_samples_leaf':list(range(1,5))}\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_grid = {'C':[0.01, 0.1, 0.5, 1, 10, 100], 'penalty':['l1','l2','elastinet']}\n",
    "knn =  KNeighborsClassifier()\n",
    "knn_grid = {'n_neighbors':list(range(2,5))}\n",
    "gnb = GaussianNB()\n",
    "gnb_grid = {}\n",
    "svm = SVC()\n",
    "svm_grid = {'kernel':['rbf'],'C':[1,10,100],'gamma':[.1,.5,1]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = GridSearchCV(estimator=dt, param_grid=dt_grid, scoring = scoring, cv=inner_cv)\n",
    "lr_clf = GridSearchCV(estimator=lr, param_grid=lr_grid, scoring = scoring, cv=inner_cv)\n",
    "knn_clf = GridSearchCV(estimator=knn, param_grid=knn_grid, scoring = scoring, cv=inner_cv)\n",
    "gnb_clf = GridSearchCV(estimator=gnb, param_grid=gnb_grid, scoring = scoring, cv=inner_cv)\n",
    "svm_clf = GridSearchCV(estimator=svm, param_grid=svm_grid, scoring = scoring, cv=inner_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_score = cross_val_score(dt_clf, X=X, y=y, cv=outer_cv)\n",
    "lr_score = cross_val_score(lr_clf, X=X, y=y, cv=outer_cv)\n",
    "knn_score = cross_val_score(knn_clf, X=X, y=y, cv=outer_cv)\n",
    "gnb_score = cross_val_score(gnb_clf, X=X, y=y, cv=outer_cv)\n",
    "svm_score = cross_val_score(svm_clf, X=X, y=y, cv=outer_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': 0.9479166666666667,\n",
       " 'lr': 0.8981481481481481,\n",
       " 'knn': 0.8304398148148149,\n",
       " 'gnb': 0.8026620370370371,\n",
       " 'svm': 0.9942129629629629}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {}\n",
    "score['dt'] = dt_score.mean()\n",
    "score['lr'] = lr_score.mean()\n",
    "score['knn'] = knn_score.mean()\n",
    "score['gnb'] = gnb_score.mean()\n",
    "score['svm'] = svm_score.mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model performs the best. I used it as my final model to further know the hyperparameter and performance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "best score:  0.9905922761162772\n",
      "[[ 74   0   0   0]\n",
      " [  0  15   0   0]\n",
      " [  2   0 241   0]\n",
      " [  0   0   0  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.97      1.00      0.99        74\n",
      "        good       1.00      1.00      1.00        15\n",
      "       unacc       1.00      0.99      1.00       243\n",
      "       vgood       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.99       346\n",
      "   macro avg       0.99      1.00      1.00       346\n",
      "weighted avg       0.99      0.99      0.99       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print('best params: ', svm_clf.best_params_)\n",
    "print('best score: ', svm_clf.best_score_)\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
